{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sushma8104/python-programs/blob/main/13_3_25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NJEDVcq1XjgB"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "def to_markdown(text):\n",
        "    text = text.replace('*', ' - ')\n",
        "    return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "Dn1YOedaYWxz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "client=genai.Client(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "0nkFdd9RZVbU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL.Image\n",
        "import google.generativeai as genai\n",
        "img = PIL.Image.open('Image.jpg')\n",
        "img\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "response = model.generate_content([\"Write a short, engaging blog post based on this picture. It should include a description of the meal in the photo and talk about my journey meal prepping.\", img],stream=True)\n",
        "response.resolve()"
      ],
      "metadata": {
        "id": "YxWJNNP3Zjvx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "Z5AJKdD8bCak",
        "outputId": "414c3f61-9340-4bd4-acd1-e3eee1c7f43d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> Here's a blog post based on the image:\n> \n> ## Meal Prepping: My Journey to a Healthier, Happier Me (And Less Time in the Kitchen!)\n> \n> Hey everyone!\n> \n> Let's be honest, sometimes the thought of cooking after a long day is enough to make you order takeout.  I used to be that person.  Dinner decisions stressed me out, and healthy eating often felt impossible. But then I discovered the magic of meal prepping!  I'm not talking about fancy gourmet meals, just simple, nutritious food that saves me time and energy throughout the week.\n> \n>  - (Image of a woman pointing enthusiastically goes here) - \n> \n> The photo above? That’s me, feeling super confident about my delicious and healthy meal prep for the week. This week's plan includes baked chicken breast with roasted vegetables (broccoli, sweet potatoes, and peppers – yum!), a big batch of quinoa salad with black beans, corn, and a zesty lime dressing, and some overnight oats for a quick breakfast.\n> \n> My meal prepping journey wasn't exactly smooth sailing. In the beginning, I felt overwhelmed.  Too many recipes, too much chopping, too much...everything!  I started small, choosing just one or two meals to prep each week.  I experimented with different recipes, figuring out what I enjoyed and what actually worked with my schedule.  Sometimes, there were flops (we've all been there!), but even those taught me valuable lessons.\n> \n> Now, I'm a full-fledged meal-prepping enthusiast!  It's more than just saving time; it's about making healthier choices.  It's about controlling exactly what goes into my food, and knowing I have delicious, nutritious options ready to go, no matter how busy my day gets.  Plus, there's something incredibly satisfying about opening my fridge and seeing a week’s worth of healthy meals waiting for me.  \n> \n> Want to give meal prepping a try? Start small, experiment, and most importantly, be kind to yourself.  It’s a journey, not a race. I'm happy to share some of my favorite simple recipes if you’re interested!  Just drop a comment below.\n"
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "6zY94VS2MqwU",
        "outputId": "367cb726-c6ee-4025-d682-b314d3c2241f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"Generate an accurate caption for this image.\", img])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "av57K6V2cpHP",
        "outputId": "1db7f752-622f-4c13-fc57-a4415bd89a9e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a caption for the image:\n",
            "\n",
            "**Option 1 (Simple):**\n",
            "\n",
            "A woman points to something off-camera, smiling confidently.\n",
            "\n",
            "**Option 2 (More descriptive):**\n",
            "\n",
            "Smiling woman in a teal patterned kurta, gesturing with her finger, suggesting an idea or pointing to something interesting.\n",
            "\n",
            "\n",
            "**Option 3 (Adding context - requires knowing the context):**\n",
            "\n",
            "\"Check out this amazing [product/deal/opportunity]!  ➡️\"\n",
            "\n",
            "\n",
            "Choose the option that best fits the intended use of the image.  If you can provide more context, I can create a more specific and effective caption.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "image_path=\"Image2.jpg\"\n",
        "image = Image.open(image_path)\n",
        "response = model.generate_content([\"Describe this image in detail.\",image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "_9JY_7YCegT9",
        "outputId": "62a63c86-2356-4f4d-d374-b014ab2a4ad1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a description of the image:\n",
            "\n",
            "Close-up view of a woman with shoulder-length, curly dark brown hair. \n",
            "\n",
            "\n",
            "She is smiling and gesturing with her right index finger, as if pointing to something off-camera or making a suggestion. Her expression is friendly and approachable. She's wearing a teal-colored, three-quarter-sleeved top with a subtle gold or light-colored print that appears to be a repeating pattern of small floral or leaf designs. The top has a simple, slightly open collar. \n",
            "\n",
            "\n",
            "The background is a plain, bright white, which keeps the focus entirely on the woman. The lighting is even and soft, preventing harsh shadows on her face.  The overall impression is a clean, bright, and positive portrait of a woman.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"What emotions can you detect in this image?\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "gx1LpBMegrTM",
        "outputId": "5655c8a5-00bd-44af-c93e-95f89b07031f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The woman in the image displays a combination of emotions:\n",
            "\n",
            "* **Happiness/Positivity:** Her smile is genuine and warm, suggesting a positive emotional state.\n",
            "* **Confidence:** Her posture and direct gaze at the camera convey confidence and self-assurance.\n",
            "* **Helpfulness/Friendliness:** The gesture of pointing suggests she's guiding or helping someone, indicative of friendliness and helpfulness.  The overall expression is approachable.\n",
            "* **Slight Playfulness:** The playful nature of pointing adds a touch of lightheartedness to her expression.\n",
            "\n",
            "\n",
            "There's no indication of negative emotions in the image.  The overall impression is one of cheerful helpfulness.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"logo1.jpg\"\n",
        "image = Image.open(image_path)\n",
        "response = model.generate_content([\"Identify the brand or company associated eith the logo..\",image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "u5w3X09qkSTf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "13e11ee4-7223-4dbc-95e6-bc60ac995aa4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That's the logo for **Amazon**.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"product.jpg\"\n",
        "image = Image.open(image_path)\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "response = model.generate_content([\"What product is shown in this image?\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "-3XLGYnwkSgH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1887b6b5-f6ea-482c-e27d-1f4943410d76"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That's a pair of black over-ear headphones.  They appear to be noise-canceling headphones, given their design and padded earcups.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"Suggest similar products to this one.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "PpyLfG-QkGGM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "outputId": "6699508a-e0d4-4da2-e9cf-9089c4251aa5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are some similar products to the black over-ear headphones shown in the image.  To give you the best recommendations, I need more information about what aspects of the headphones are most important to you.  However, I can suggest some general categories and examples:\n",
            "\n",
            "**Similar in Style & Features (Assuming Noise-Cancelling is NOT a primary feature):**\n",
            "\n",
            "* **Other Closed-Back Over-Ear Headphones:**  Look for headphones with a similar design:  closed-back (covering the ear completely), over-ear (cups sit over the ears), and a similar build quality. Brands like Sony, Audio-Technica, Sennheiser, AKG, and Beyerdynamic all offer many models in this style.  Look for keywords like \"studio headphones\" or \"professional headphones\" for similar sound quality.\n",
            "\n",
            "\n",
            "**If Noise-Cancelling is Important:**\n",
            "\n",
            "* **Noise-Cancelling Over-Ear Headphones:** Brands like Sony (WH-1000XM series), Bose (QuietComfort series), and Apple (AirPods Max) are known for their excellent noise cancellation.\n",
            "\n",
            "\n",
            "**If Budget is a Factor:**\n",
            "\n",
            "* **Budget-Friendly Over-Ear Headphones:**  Many brands offer excellent quality at lower price points.  Look at models from Anker, COWIN, and Soundcore by Anker.\n",
            "\n",
            "\n",
            "**To refine my suggestions, tell me:**\n",
            "\n",
            "* **Your budget:** How much are you willing to spend?\n",
            "* **Primary use:**  Will you use these for music, gaming, calls, or something else?\n",
            "* **Sound quality preferences:** Do you prefer bass-heavy, balanced, or bright sound?\n",
            "* **Features you need:** Are noise-canceling, Bluetooth connectivity, a microphone, or a carrying case essential?\n",
            "* **Comfort level:** How long will you wear them for?\n",
            "\n",
            "\n",
            "Once I have this information, I can provide more specific and helpful recommendations.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"invoice.jpg\"\n",
        "image = Image.open(image_path)\n",
        "response = model.generate_content([\"Extract the price from this image.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "uX1UOdj2Pocs",
        "outputId": "a59cca1c-2bbb-4da5-d67d-cc0d3f8b8e95"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The price of each item is $10.00.  The sub-total is $100.00, and the grand total, including a 10% tax, is also $100.00.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"Extract the price, currency, and any discounts from this image.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "OXtYVI9kS915",
        "outputId": "81c3f563-acdc-4bc0-e45a-3c4cd80d4d54"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's the extracted information from the invoice image:\n",
            "\n",
            "* **Price:** $10.00 (per item)\n",
            "* **Currency:** USD ($)\n",
            "* **Discounts:**  None explicitly stated.  The Grand Total is the same as the Subtotal, however, there is a 10% tax applied.  It's possible that the 10% tax is included within the stated prices, making the net price lower than $10.00 per item.  Without further details, we cannot definitively say a discount exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"bicycle.jpg\"\n",
        "image = Image.open(image_path)\n",
        "response = model.generate_content([\"Identify all objects in this image.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "LRsoKh8WTCgK",
        "outputId": "dbdff72f-9c17-4787-c0ae-cb444b135246"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a list of the objects identified in the image:\n",
            "\n",
            "* **Two men:** Riding bicycles.  One in a blue shirt and camouflage shorts, the other in a grey shirt and jeans.\n",
            "* **Two bicycles:**  One is predominantly yellow and black, the other is white.  Both appear to be hybrid/city bikes.\n",
            "* **A motorcycle:** Parked on the left side of the image.\n",
            "* **A building:** A building with a roller shutter door, windows, and a visible portion of the interior.\n",
            "* **Chairs:** Two chairs are visible inside the building.\n",
            "* **A man (in the background):**  Sitting inside the building, seemingly observing the cyclists.\n",
            "* **Street:** A wet street surface.\n",
            "* **Vegetation:** Some grass is visible along the curb.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image=Image.open(\"items.jpg\")\n",
        "response=model.generate_content([\"List all objects in this image and count how many of each are present.\",image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "-VeWsDysThM3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "3d0fb15c-34f3-42a6-a426-366e591a3ab5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a count of the objects in the image:\n",
            "\n",
            "**Countables:**\n",
            "\n",
            "* Eggs: 3\n",
            "* Banana: 1\n",
            "* Olives: 2\n",
            "* Fries: 1 (portion)\n",
            "* Burger: 1\n",
            "* Hot dog: 1\n",
            "* Apple: 1\n",
            "* Carrots: 2\n",
            "* Tomatoes: 3\n",
            "* Watermelon: 1\n",
            "\n",
            "\n",
            "**Uncountables:**\n",
            "\n",
            "* Milk: 1 (bottle)\n",
            "* Flour: 1 (bag)\n",
            "* Salt: 1 (container)\n",
            "* Sugar: 1 (container)\n",
            "* Jam: 1 (jar)\n",
            "* Meat: 2 (pieces)\n",
            "* Rice: 1 (pile)\n",
            "* Honey: 1 (jar)\n",
            "* Tea: 1 (cup)\n",
            "* Cheese: 1 (slice)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install youtube-transcript-api pytube"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "At02mb3RWZeh",
        "outputId": "5f26b507-2426-4ac9-fc07-43930579a056"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube-transcript-api\n",
            "  Downloading youtube_transcript_api-1.0.1-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api) (0.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (2025.1.31)\n",
            "Downloading youtube_transcript_api-1.0.1-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube, youtube-transcript-api\n",
            "Successfully installed pytube-15.0.0 youtube-transcript-api-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "_F_Ng7NUYEUm"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_video_insights(text):\n",
        "    \"\"\"Extracts key insights from the YouTube video transcript.\"\"\"\n",
        "    model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "    prompt = f\"Extract the key takeaways and insights from this YouTube video:\\n\\n{text}\"\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text\n",
        "\n",
        "insights = extract_video_insights(video_transcript)\n",
        "print(\"Key Insights:\\n\",insights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "S3GID-ZSW-c-",
        "outputId": "46a2dc71-034e-4f42-9300-7ee57646ef7a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Key Insights:\n",
            " Since there is no YouTube video provided, there are no key takeaways or insights to extract.  Please provide a link to the YouTube video.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hReJwVYnXx_2"
      },
      "execution_count": 36,
      "outputs": []
    }
  ]
}